{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "259c98f5",
   "metadata": {},
   "source": [
    "Step 1: We import stuff that we needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3796da5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Imported essential modules and functionality\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoderLayer, TransformerDecoder\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.optim import Adam\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "print(\"###Imported essential modules and functionality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f437c894",
   "metadata": {},
   "source": [
    "Step 2: We now define the Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54b36cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerAutoencoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 encoder_input_dim, \n",
    "                 decoder_input_dim, \n",
    "                 hidden_dim,\n",
    "                 num_heads, \n",
    "                 encoder_embedding_dim, \n",
    "                 decoder_embedding_dim,\n",
    "                 num_layers, \n",
    "                 dropout):\n",
    "        super(TransformerAutoencoder, self).__init__()\n",
    "        self.encoder_input_dim = encoder_input_dim\n",
    "        self.decoder_input_dim = decoder_input_dim\n",
    "        self.encoder_embedding_dim = encoder_embedding_dim\n",
    "        self.decoder_embedding_dim = decoder_embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "\n",
    "        # Encoder Embedding\n",
    "        self.encoder_embedding = nn.Linear(self.encoder_input_dim, self.encoder_embedding_dim)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder_layer = TransformerEncoderLayer(d_model=self.encoder_embedding_dim,\n",
    "                                                     nhead=self.num_heads,\n",
    "                                                     dim_feedforward=self.hidden_dim,\n",
    "                                                     dropout=self.dropout,\n",
    "                                                     batch_first=True)\n",
    "        self.encoder = TransformerEncoder(self.encoder_layer,\n",
    "                                          num_layers=self.num_layers)\n",
    "\n",
    "        # Decoder Embedding\n",
    "        self.decoder_embedding = nn.Linear(self.decoder_input_dim, self.decoder_embedding_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder_layer = TransformerDecoderLayer(d_model=self.decoder_embedding_dim,\n",
    "                                                     nhead=self.num_heads,\n",
    "                                                     dim_feedforward=self.hidden_dim,\n",
    "                                                     dropout=self.dropout,\n",
    "                                                     batch_first=True)\n",
    "        self.decoder = TransformerDecoder(self.decoder_layer, num_layers=self.num_layers)\n",
    "\n",
    "        # Final output layer\n",
    "        self.out = nn.Linear(self.decoder_embedding_dim, self.decoder_input_dim)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # Use the mask to create a version of x with missing values set to zero.\n",
    "        \n",
    "        # Encode the masked input.\n",
    "        x = self.encoder_embedding(x)\n",
    "        x_encoded = self.encoder(x)\n",
    "\n",
    "        # Decode the encoded representation.\n",
    "        y = self.decoder_embedding(y)\n",
    "        x_decoded = self.decoder(y, x_encoded)\n",
    "\n",
    "        # Apply the final output layer\n",
    "        x_out = self.out(x_decoded)\n",
    "\n",
    "        return x_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0918f37",
   "metadata": {},
   "source": [
    "Step 3: We define our torch DataSet Class for our measurements Y_data and\n",
    "target values X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23bcf446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Defined Classes TransformerAutoEncoder, GridDataset\n"
     ]
    }
   ],
   "source": [
    "class GridDataset(Dataset):\n",
    "    def _load_data_from_memory(self):\n",
    "        pass\n",
    "    def __init__(self, inputData, targetData):\n",
    "        # if data is passed with Y_data then this is the input measurements, the estimated states\n",
    "        # if data is passed with X_data then this is the target, the groundtruth values\n",
    "        self.num_samples = inputData.shape[0]\n",
    "        self.input_dim = inputData.shape[2]\n",
    "        self.output_dim = targetData.shape[2]\n",
    "\n",
    "        self.inputs = inputData # features is target\n",
    "\n",
    "        # apply mask of missing features to the feature set\n",
    "        # temp_mask = torch.ones(self.num_samples, self.input_dim)\n",
    "        # temp_mask[:, [0, 1, 16, 17, 24, 25]] = 0 # index of buses missing measurements.\n",
    "        # self.mask = temp_mask # index of buses missing measurements.\n",
    "        # self.mask = self.mask.float()\n",
    "        # self.features = self.features * self.mask\n",
    "\n",
    "        # targets\n",
    "        self.targets = targetData\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]\n",
    "    \n",
    "    print(\"###Defined Classes TransformerAutoEncoder, GridDataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19de411c",
   "metadata": {},
   "source": [
    "Step 4: We then import the data necessary excluding the initial condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Loaded data\n"
     ]
    }
   ],
   "source": [
    "datachoice = \"Lorenz\" # $$ acceptable values Lorrentz, KS, Burgers\n",
    "\n",
    "if datachoice==\"Lorenz\":\n",
    "    datafile = \"../Data/lorenz_data.npz\" # also there is \"Data/lorenz_data_diff_ic.npz\"\n",
    "    \n",
    "\n",
    "# elif datachoice==\"KS\":\n",
    "#     datafile = \"Data/ks_data.npz\"\n",
    "#     # TODO\n",
    "# elif datachoice==\"burgers\":\n",
    "#     datafile= \"Data/burgers_data.npz\"\n",
    "#     # TODO\n",
    "\n",
    "\n",
    "rawData = np.load(datafile)\n",
    "allInputs = torch.Tensor(rawData[\"Y_data\"])\n",
    "allTargets = torch.Tensor(rawData[\"X_data\"])\n",
    "# TODO \n",
    "# exclude initial condition. issue: [1:] makes num samples from 1 to 49 avaialbl and not 1 to 1001 \n",
    "print(\"## Loaded data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41893b8",
   "metadata": {},
   "source": [
    "Step 4: We do the splitting of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07d4c9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Split the data:\n",
      "\n",
      "Training data set size   : 40\n",
      " Validation data set size : 5\n",
      " Test data set size       : 5\n",
      "torch.Size([1001, 1])\n"
     ]
    }
   ],
   "source": [
    "gridDataSet = GridDataset(allInputs, allTargets)\n",
    "trainPercent = 0.8\n",
    "testPercent = 0.1\n",
    "validatePercent = 0.1\n",
    "data = [d for d in gridDataSet]\n",
    "splitDataList = random_split(gridDataSet, [trainPercent, testPercent, validatePercent], torch.Generator().manual_seed(42))\n",
    "\n",
    "trainingData = splitDataList[0]\n",
    "testingData = splitDataList[1]\n",
    "validatingData = splitDataList[2]\n",
    "lenTrainingData = len(trainingData)\n",
    "lenTestingData = len(testingData)\n",
    "lenValidatingData = len(validatingData)\n",
    "print(\"## Split the data:\\n\")\n",
    "print(f\"Training data set size   : {lenTrainingData}\\n\",\n",
    "      f\"Validation data set size : {lenTestingData}\\n\",\n",
    "      f\"Test data set size       : {lenValidatingData}\")\n",
    "\n",
    "trainingTensorDataSet = TensorDataset(trainingData.dataset.inputs,\n",
    "                                      trainingData.dataset.targets)\n",
    "testingTensorDataSet = TensorDataset(testingData.dataset.inputs,\n",
    "                                      testingData.dataset.targets)\n",
    "validatingTensorDataSet = TensorDataset(validatingData.dataset.inputs,\n",
    "                                      validatingData.dataset.targets)\n",
    "\n",
    "print(trainingData[0][0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93a4fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateLossFromTrainingData(train_dataloader, criterion):\n",
    "    sum_loss = 0\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        inputs, targets = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, targets)\n",
    "        loss = criterion(outputs, targets)\n",
    "        sum_loss+=loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    avg_loss = sum_loss/len(train_dataloader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ab1f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Store best results\n",
    "best_result = dict({\n",
    "    'model':[],\n",
    "    'learn_rate':[],\n",
    "    'num_epochs':[],\n",
    "    'encoder_embedding_dim':[],\n",
    "    'decoder_embedding_dim':[],\n",
    "    'hidden_dim':[],\n",
    "    'num_heads':[],\n",
    "    'weight_decay':[],\n",
    "    'dropout':[],\n",
    "    'avg_training_loss':[],\n",
    "    'best_validation_loss':[]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7bab5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH NUMBER: 1\n",
      "AVERAGE TRAINING LOSS  : 226.04327850341798\n",
      "AVERAGE VALIDATION LOSS: 206.39358215332032\n",
      "BEST VALIDATION LOSS: 206.39358215332032 at EPOCH 1\n",
      "EPOCH NUMBER: 2\n",
      "AVERAGE TRAINING LOSS  : 192.12095336914064\n",
      "AVERAGE VALIDATION LOSS: 172.75513458251953\n",
      "BEST VALIDATION LOSS: 172.75513458251953 at EPOCH 2\n",
      "EPOCH NUMBER: 3\n",
      "AVERAGE TRAINING LOSS  : 157.1037139892578\n",
      "AVERAGE VALIDATION LOSS: 136.71775817871094\n",
      "BEST VALIDATION LOSS: 136.71775817871094 at EPOCH 3\n",
      "EPOCH NUMBER: 4\n",
      "AVERAGE TRAINING LOSS  : 121.9678466796875\n",
      "AVERAGE VALIDATION LOSS: 104.11313400268554\n",
      "BEST VALIDATION LOSS: 104.11313400268554 at EPOCH 4\n",
      "EPOCH NUMBER: 5\n",
      "AVERAGE TRAINING LOSS  : 93.25796432495117\n",
      "AVERAGE VALIDATION LOSS: 81.54179306030274\n",
      "BEST VALIDATION LOSS: 81.54179306030274 at EPOCH 5\n",
      "EPOCH NUMBER: 6\n",
      "AVERAGE TRAINING LOSS  : 76.32467803955078\n",
      "AVERAGE VALIDATION LOSS: 71.43019256591796\n",
      "BEST VALIDATION LOSS: 71.43019256591796 at EPOCH 6\n",
      "EPOCH NUMBER: 7\n",
      "AVERAGE TRAINING LOSS  : 68.20082931518554\n",
      "AVERAGE VALIDATION LOSS: 59.392757415771484\n",
      "BEST VALIDATION LOSS: 59.392757415771484 at EPOCH 7\n",
      "EPOCH NUMBER: 8\n",
      "AVERAGE TRAINING LOSS  : 53.80459823608398\n",
      "AVERAGE VALIDATION LOSS: 46.65436210632324\n",
      "BEST VALIDATION LOSS: 46.65436210632324 at EPOCH 8\n",
      "EPOCH NUMBER: 9\n",
      "AVERAGE TRAINING LOSS  : 51.52057876586914\n",
      "AVERAGE VALIDATION LOSS: 47.79451637268066\n",
      "EPOCH NUMBER: 10\n",
      "AVERAGE TRAINING LOSS  : 43.437324142456056\n",
      "AVERAGE VALIDATION LOSS: 41.21464233398437\n",
      "BEST VALIDATION LOSS: 41.21464233398437 at EPOCH 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define constants\n",
    "encoder_input_dim = gridDataSet.input_dim\n",
    "decoder_input_dim = gridDataSet.output_dim\n",
    "output_dim = gridDataSet.output_dim\n",
    "num_layers = 4\n",
    "parameters = dict(num_epochs = [64],\n",
    "                  hidden_dim = [64],\n",
    "                  num_heads = [4],\n",
    "                  encoder_embedding_dim = [16],\n",
    "                  decoder_embedding_dim = [16],\n",
    "                  learn_rate = [0.1],\n",
    "                  weight_decay = [0.005],\n",
    "                  dropout = [0.05])\n",
    "\n",
    "param_values = [v for v in parameters.values()]\n",
    "\n",
    "for run_id, (num_epochs,\n",
    "             hidden_dim,\n",
    "             num_heads,\n",
    "             encoder_embedding_dim, \n",
    "             decoder_embedding_dim,\n",
    "             learn_rate,\n",
    "             weight_decay, \n",
    "             dropout) in enumerate(product(*param_values)):\n",
    "    criterion = nn.MSELoss()\n",
    "    trainDataSetLoader =  DataLoader(trainingTensorDataSet, batch_size = 5, shuffle = True)\n",
    "    validationDataSetLoader = DataLoader(validatingTensorDataSet, batch_size = 5, shuffle = True)\n",
    "\n",
    "    model = TransformerAutoencoder(encoder_input_dim, \n",
    "                                   decoder_input_dim,\n",
    "                                   hidden_dim, \n",
    "                                   num_heads, \n",
    "                                   encoder_embedding_dim,\n",
    "                                   decoder_embedding_dim, \n",
    "                                   num_layers, \n",
    "                                   dropout)\n",
    "    optimizer = Adam(model.parameters(), lr=learn_rate, weight_decay=weight_decay)\n",
    "    best_validation_loss = 1_000_000.\n",
    "    avg_training_loss = 0.\n",
    "    avg_validation_loss = 0.\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"EPOCH NUMBER: {epoch+1}\")\n",
    "        model.train(True)\n",
    "        avg_training_loss = evaluateLossFromTrainingData(trainDataSetLoader, criterion)\n",
    "        model.eval()\n",
    "        sum_validation_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(validationDataSetLoader):\n",
    "                inputs, targets = batch\n",
    "                outputs = model(inputs, targets)\n",
    "                val_loss = criterion(outputs, targets)\n",
    "                sum_validation_loss += val_loss.item()\n",
    "        avg_validation_loss = sum_validation_loss / len(validationDataSetLoader)\n",
    "        print(f\"AVERAGE TRAINING LOSS  : {avg_training_loss}\\nAVERAGE VALIDATION LOSS: {avg_validation_loss}\")\n",
    "\n",
    "        if avg_validation_loss < best_validation_loss:\n",
    "            best_validation_loss = avg_validation_loss\n",
    "            print(f'BEST VALIDATION LOSS: {best_validation_loss} at EPOCH {epoch+1}')\n",
    "            best_result['model']=model.state_dict()\n",
    "            best_result['learn_rate']=learn_rate\n",
    "            best_result['encoder_embedding_dim']=encoder_embedding_dim\n",
    "            best_result['decoder_embedding_dim'] =decoder_embedding_dim\n",
    "            best_result['num_epochs']=num_epochs\n",
    "            best_result['hidden_dim']=hidden_dim\n",
    "            best_result['num_heads']=num_heads\n",
    "            best_result['weight_decay']=weight_decay\n",
    "            best_result['dropout']=dropout\n",
    "            best_result['avg_training_loss']=avg_training_loss\n",
    "            best_result['best_validation_loss']=best_validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84765b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerAutoencoder(\n",
      "  (encoder_embedding): Linear(in_features=1, out_features=16, bias=True)\n",
      "  (encoder_layer): TransformerEncoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=16, out_features=64, bias=True)\n",
      "    (dropout): Dropout(p=0.05, inplace=False)\n",
      "    (linear2): Linear(in_features=64, out_features=16, bias=True)\n",
      "    (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.05, inplace=False)\n",
      "    (dropout2): Dropout(p=0.05, inplace=False)\n",
      "  )\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=16, out_features=64, bias=True)\n",
      "        (dropout): Dropout(p=0.05, inplace=False)\n",
      "        (linear2): Linear(in_features=64, out_features=16, bias=True)\n",
      "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.05, inplace=False)\n",
      "        (dropout2): Dropout(p=0.05, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder_embedding): Linear(in_features=3, out_features=16, bias=True)\n",
      "  (decoder_layer): TransformerDecoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
      "    )\n",
      "    (multihead_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=16, out_features=64, bias=True)\n",
      "    (dropout): Dropout(p=0.05, inplace=False)\n",
      "    (linear2): Linear(in_features=64, out_features=16, bias=True)\n",
      "    (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.05, inplace=False)\n",
      "    (dropout2): Dropout(p=0.05, inplace=False)\n",
      "    (dropout3): Dropout(p=0.05, inplace=False)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=16, out_features=64, bias=True)\n",
      "        (dropout): Dropout(p=0.05, inplace=False)\n",
      "        (linear2): Linear(in_features=64, out_features=16, bias=True)\n",
      "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.05, inplace=False)\n",
      "        (dropout2): Dropout(p=0.05, inplace=False)\n",
      "        (dropout3): Dropout(p=0.05, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (out): Linear(in_features=16, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "min_loss_model = TransformerAutoencoder(encoder_input_dim, \n",
    "                                        decoder_input_dim, \n",
    "                                        hidden_dim, \n",
    "                                        num_heads,\n",
    "                                        encoder_embedding_dim, \n",
    "                                        decoder_embedding_dim, \n",
    "                                        num_layers, \n",
    "                                        dropout)\n",
    "\n",
    "min_loss_model.load_state_dict(best_result[\"model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1274ef",
   "metadata": {},
   "source": [
    "Step 5: Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "440a23fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataSetLoader, criterion):\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    sum_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataSetLoader:\n",
    "            inputs, targets = batch\n",
    "            prediction = model(inputs, targets)\n",
    "            predictions.append(prediction)\n",
    "            labels.append(targets)\n",
    "            test_loss = criterion(prediction,targets)\n",
    "            sum_loss+=test_loss\n",
    "        avg_test_loss = sum_loss/len(dataSetLoader)\n",
    "    \n",
    "    print(f\"AVERATE TEST LOSS: {avg_test_loss}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c592d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERATE TEST LOSS: 41.233917236328125\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "predict(min_loss_model, testingTensorDataSet,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5011ca40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7.3766,  8.4234, 26.1450],\n",
      "        [ 7.0173,  7.9017, 26.4439],\n",
      "        [ 7.0534,  8.2067, 25.8682],\n",
      "        ...,\n",
      "        [-5.2139, -4.9795, 23.9318],\n",
      "        [-4.9670, -4.7275, 24.3176],\n",
      "        [ 7.1414,  8.0633, 26.2787]])\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
